name: CI

on:
  push:
    branches:
      - '**'
  pull_request:
    branches:
      - '**'
  workflow_dispatch:

permissions:
  contents: read

jobs:
  test:
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
    permissions:
      contents: read
      checks: write
      pull-requests: write
      issues: write
    steps:
      - name: Checkout repository (with submodules)
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install system packages (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libsndfile1

      - name: Install system packages (macOS)
        if: runner.os == 'macOS'
        run: |
          brew update
          brew install libsndfile

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Patch ft8_lib Makefile for proper link order
        run: |
          sed -i -E 's/^(\t\$\(CC\) \$\(LDFLAGS\) -o \$@ \$\^)/\1 \$\(LDLIBS\)/' external/ft8_lib/Makefile

      - name: Build ft8_lib decoder (Linux)
        if: runner.os == 'Linux'
        run: |
          make -C external/ft8_lib clean
          make -C external/ft8_lib decode_ft8 CFLAGS="-D_POSIX_C_SOURCE=200809L" LDFLAGS="" LDLIBS="-lrt -lm"

      - name: Build ft8_lib decoder (macOS)
        if: runner.os == 'macOS'
        run: |
          make -C external/ft8_lib clean
          make -C external/ft8_lib decode_ft8 CFLAGS="-D_DARWIN_C_SOURCE -D_POSIX_C_SOURCE=200809L" LDFLAGS="" LDLIBS="-lm"

      - name: Run tests
        run: |
          mkdir -p reports
          set -o pipefail
          pytest -vv -ra --durations=0 --maxfail=1 --color=yes --capture=tee-sys --junitxml=reports/junit.xml --log-file=reports/pytest.log --log-file-level=INFO 2>&1 | tee reports/pytest.out

      - name: Summarize short regression decodes
        if: always()
        run: |
          echo "### Short Regression Decodes" >> "$GITHUB_STEP_SUMMARY"
          src_file=""
          if [ -f reports/pytest.out ]; then src_file=reports/pytest.out; elif [ -f reports/pytest.log ]; then src_file=reports/pytest.log; fi
          if [ -n "$src_file" ]; then
            line=$(grep -F "SHORT TOTAL:" "$src_file" | tail -n 1 || true)
            if [ -n "$line" ]; then
              pe=$(printf "%s" "$line" | sed -n 's/.*pos_expected=\([0-9][0-9]*\).*/\1/p')
              pm=$(printf "%s" "$line" | sed -n 's/.*pos_matched=\([0-9][0-9]*\).*/\1/p')
              if [ -n "$pe" ] && [ -n "$pm" ]; then
                pct=$(awk -v pm="$pm" -v pe="$pe" 'BEGIN { if (pe>0) printf "%.1f", (pm/pe*100); }')
                if [ -n "$pct" ]; then
                  echo "Matched: ${pm} / ${pe} (${pct}%)" >> "$GITHUB_STEP_SUMMARY"
                else
                  echo "Matched: ${pm} / ${pe}" >> "$GITHUB_STEP_SUMMARY"
                fi
              else
                echo "Totals line found, but could not parse numbers." >> "$GITHUB_STEP_SUMMARY"
              fi
            else
              echo "Short regression totals not found in output (test may have been skipped)." >> "$GITHUB_STEP_SUMMARY"
            fi
          else
            echo "Pytest output/log not found." >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ${{ runner.os }}-test-reports
          path: reports

      - name: Publish unit test results
        if: always() && runner.os == 'Linux'
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: reports/junit.xml
          github_token: ${{ secrets.GITHUB_TOKEN }}
          check_name: 'Unit Test Results'

      - name: Comment short regression decodes on PR
        if: always() && github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          src_file=""
          if [ -f reports/pytest.out ]; then src_file=reports/pytest.out; elif [ -f reports/pytest.log ]; then src_file=reports/pytest.log; fi
          title="Short Regression Decodes"
          body="Short Regression Decodes:\n"
          if [ -n "$src_file" ]; then
            line=$(grep -F "SHORT TOTAL:" "$src_file" | tail -n 1 || true)
            if [ -n "$line" ]; then
              pe=$(printf "%s" "$line" | sed -n 's/.*pos_expected=\([0-9][0-9]*\).*/\1/p')
              pm=$(printf "%s" "$line" | sed -n 's/.*pos_matched=\([0-9][0-9]*\).*/\1/p')
              if [ -n "$pe" ] && [ -n "$pm" ]; then
                pct=$(awk -v pm="$pm" -v pe="$pe" 'BEGIN { if (pe>0) printf "%.1f", (pm/pe*100); }')
                if [ -n "$pct" ]; then
                  body+="Matched: ${pm} / ${pe} (${pct}%)\n"
                else
                  body+="Matched: ${pm} / ${pe}\n"
                fi
              else
                body+="Totals line found, but could not parse numbers.\n"
              fi
            else
              body+="Short regression totals not found in output (test may have been skipped).\n"
            fi
          else
            body+="Pytest output/log not found.\n"
          fi

          # Find existing comment by this workflow to update (idempotent)
          pr_number=${{ github.event.number }}
          repo=${{ github.repository }}
          existing_id=$(gh api repos/$repo/issues/$pr_number/comments --jq '.[] | select(.user.login == "github-actions[bot]") | select(.body | contains("'"$title"'")) | .id' | head -n1 || true)
          if [ -n "$existing_id" ]; then
            gh api repos/$repo/issues/comments/$existing_id -X PATCH -f body="$body"
          else
            gh api repos/$repo/issues/$pr_number/comments -X POST -f body="$body"
          fi


